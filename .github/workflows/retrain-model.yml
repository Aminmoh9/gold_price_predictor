# . github/workflows/retrain-model.yml
# Automated weekly model retraining with deployment to S3 (Serverless - No EC2 24/7 required)

name: Weekly Model Retrain

on:
  schedule:
    # Every Sunday at 2:00 AM UTC
    - cron: '0 2 * * 0'
  
  # Allow manual trigger from GitHub UI
  workflow_dispatch: 

env:
  PYTHON_VERSION: '3.12'
  TF_CPP_MIN_LOG_LEVEL: '2'

jobs:
  retrain: 
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    env:
      AWS_REGION: ${{ secrets.AWS_REGION }}
      SNS_RETRAIN_ARN: ${{ secrets.SNS_RETRAIN_ARN }}
      TF_CPP_MIN_LOG_LEVEL: '2'

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Debug - Check secrets
        run: |
          echo "üîç Checking secret configuration..."
          echo "AWS_REGION is set: ${{ secrets.AWS_REGION != '' }}"
          echo "AWS_ACCESS_KEY_ID is set: ${{ secrets.AWS_ACCESS_KEY_ID != '' }}"
          echo "AWS_SECRET_ACCESS_KEY is set: ${{ secrets.AWS_SECRET_ACCESS_KEY != '' }}"
          echo "S3_BUCKET is set: ${{ secrets.S3_BUCKET != '' }}"
          echo "SNS_RETRAIN_ARN is set: ${{ secrets.SNS_RETRAIN_ARN != '' }}"
          if [ -n "$AWS_REGION" ]; then
            echo "AWS_REGION value length: ${#AWS_REGION}"
          else
            echo "‚ö†Ô∏è AWS_REGION is empty!"
          fi
        env:
          AWS_REGION: ${{ secrets.AWS_REGION }}

      - name: Validate required secrets
        run: |
          MISSING_SECRETS=()
          
          if [ -z "${{ secrets.AWS_REGION }}" ]; then
            MISSING_SECRETS+=("AWS_REGION")
          fi
          
          if [ -z "${{ secrets.AWS_ACCESS_KEY_ID }}" ]; then
            MISSING_SECRETS+=("AWS_ACCESS_KEY_ID")
          fi
          
          if [ -z "${{ secrets.AWS_SECRET_ACCESS_KEY }}" ]; then
            MISSING_SECRETS+=("AWS_SECRET_ACCESS_KEY")
          fi
          
          if [ -z "${{ secrets.S3_BUCKET }}" ]; then
            MISSING_SECRETS+=("S3_BUCKET")
          fi
          
          if [ ${#MISSING_SECRETS[@]} -gt 0 ]; then
            echo "‚ùå ERROR: The following required secrets are missing or empty:"
            printf '  - %s\n' "${MISSING_SECRETS[@]}"
            echo ""
            echo "Please set these secrets in:  Settings ‚Üí Secrets and variables ‚Üí Actions"
            echo "Repository: https://github.com/${{ github.repository }}/settings/secrets/actions"
            exit 1
          fi
          
          echo "‚úÖ All required secrets are configured"

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run training script
        id: training
        run: |
          python src/gold_price_train.py
          echo "Training completed successfully"

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Upload model to S3
        run: |
          TIMESTAMP=$(date +%Y%m%d_%H%M%S)
          
          # Upload new model with timestamp (for versioning)
          aws s3 cp models/gold_lstm_model.keras s3://${{ secrets.S3_BUCKET }}/models/gold_lstm_model_${TIMESTAMP}.keras
          aws s3 cp models/gold_scaler.pkl s3://${{ secrets.S3_BUCKET }}/models/gold_scaler_${TIMESTAMP}.pkl
          aws s3 cp models/model_metadata.json s3://${{ secrets.S3_BUCKET }}/models/model_metadata_${TIMESTAMP}.json
          
          # Upload as "latest" (EC2 will pull this on startup)
          aws s3 cp models/gold_lstm_model.keras s3://${{ secrets.S3_BUCKET }}/models/latest/gold_lstm_model.keras
          aws s3 cp models/gold_scaler.pkl s3://${{ secrets.S3_BUCKET }}/models/latest/gold_scaler.pkl
          aws s3 cp models/model_metadata.json s3://${{ secrets.S3_BUCKET }}/models/latest/model_metadata.json
          
          echo "‚úÖ Models uploaded to S3"

      - name: Read training metrics
        id: metrics
        run: |
          MAPE=$(cat models/model_metadata.json | python -c "import sys, json; print(json.load(sys.stdin).get('mape', 'N/A'))")
          echo "mape=$MAPE" >> $GITHUB_OUTPUT

      - name: Send success notification
        if: success() && secrets.SNS_RETRAIN_ARN != ''
        run: |
          aws sns publish \
            --topic-arn "${{ secrets.SNS_RETRAIN_ARN }}" \
            --region "${{ secrets.AWS_REGION }}" \
            --subject "‚úÖ Gold Model Retrained Successfully" \
            --message "Model retraining completed on $(date).

          MAPE: ${{ steps.metrics.outputs.mape }}%
          
          New model uploaded to S3: ${{ secrets.S3_BUCKET }}/models/latest/
          
          View workflow:  ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"

      - name: Log success (no SNS)
        if: success() && secrets.SNS_RETRAIN_ARN == ''
        run: |
          echo "‚úÖ Model retraining completed successfully!"
          echo "MAPE: ${{ steps.metrics.outputs.mape }}%"
          echo "‚ö†Ô∏è SNS_RETRAIN_ARN not configured - skipping notification"

      - name: Send failure notification
        if: failure() && secrets.SNS_RETRAIN_ARN != ''
        run: |
          aws sns publish \
            --topic-arn "${{ secrets.SNS_RETRAIN_ARN }}" \
            --region "${{ secrets.AWS_REGION }}" \
            --subject "‚ùå Gold Model Retraining Failed" \
            --message "Model retraining failed on $(date).
          
          Check the workflow logs: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"

      - name: Log failure (no SNS)
        if: failure() && secrets.SNS_RETRAIN_ARN == ''
        run: |
          echo "‚ùå Model retraining failed!"
          echo "‚ö†Ô∏è SNS_RETRAIN_ARN not configured - skipping notification"