# .github/workflows/retrain-model.yml
# Automated weekly model retraining with deployment to S3 (Serverless - No EC2 24/7 required)

name: Weekly Model Retrain

on:
  schedule:
    # Every Sunday at 2:00 AM UTC
    - cron: '0 2 * * 0'
  
  # Allow manual trigger from GitHub UI
  workflow_dispatch:

env:
  PYTHON_VERSION: '3.12'
  TF_CPP_MIN_LOG_LEVEL: '2'

jobs:
  retrain:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    env:
      AWS_REGION: ${{ secrets.AWS_REGION }}
      SNS_TOPIC_ARN: ${{ secrets.SNS_TOPIC_ARN }}
      TF_CPP_MIN_LOG_LEVEL: '2'

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Debug AWS secrets
        run: |
          echo "AWS_REGION is set: ${{ secrets.AWS_REGION != '' }}"
          echo "SNS_RETRAIN_ARN is set: ${{ secrets.SNS_RETRAIN_ARN != '' }}"
          echo "AWS_ACCESS_KEY_ID is set: ${{ secrets.AWS_ACCESS_KEY_ID != '' }}"
          echo "AWS_SECRET_ACCESS_KEY is set: ${{ secrets.AWS_SECRET_ACCESS_KEY != '' }}"
          echo "S3_BUCKET is set: ${{ secrets.S3_BUCKET != '' }}"

      - name: Validate AWS secrets
        run: |
          MISSING_SECRETS=()
          
          if [ -z "$AWS_REGION" ]; then
            echo "‚ùå ERROR: AWS_REGION secret is not set or is empty"
            MISSING_SECRETS+=("AWS_REGION")
          fi
          
          if [ -z "$AWS_ACCESS_KEY_ID" ]; then
            echo "‚ùå ERROR: AWS_ACCESS_KEY_ID secret is not set or is empty"
            MISSING_SECRETS+=("AWS_ACCESS_KEY_ID")
          fi
          
          if [ -z "$AWS_SECRET_ACCESS_KEY" ]; then
            echo "‚ùå ERROR: AWS_SECRET_ACCESS_KEY secret is not set or is empty"
            MISSING_SECRETS+=("AWS_SECRET_ACCESS_KEY")
          fi
          
          if [ -z "$S3_BUCKET" ]; then
            echo "‚ùå ERROR: S3_BUCKET secret is not set or is empty"
            MISSING_SECRETS+=("S3_BUCKET")
          fi
          
          if [ -z "$SNS_RETRAIN_ARN" ]; then
            echo "‚ö†Ô∏è WARNING: SNS_RETRAIN_ARN secret is not set - notifications will be skipped"
          fi
          
          if [ ${#MISSING_SECRETS[@]} -gt 0 ]; then
            echo ""
            echo "üìã Missing required secrets: ${MISSING_SECRETS[*]}"
            echo "Please configure these secrets in GitHub repository settings:"
            echo "Settings ‚Üí Secrets and variables ‚Üí Actions ‚Üí Repository secrets"
            exit 1
          fi
          
          echo "‚úÖ Required AWS secrets validated"
        env:
          AWS_REGION: ${{ secrets.AWS_REGION }}
          SNS_RETRAIN_ARN: ${{ secrets.SNS_RETRAIN_ARN }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          S3_BUCKET: ${{ secrets.S3_BUCKET }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run training script
        id: training
        run: |
          python src/gold_price_train.py
          echo "Training completed successfully"

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Upload model to S3
        run: |
          TIMESTAMP=$(date +%Y%m%d_%H%M%S)
          
          # Upload new model with timestamp (for versioning)
          aws s3 cp models/gold_lstm_model.keras s3://${{ secrets.S3_BUCKET }}/models/gold_lstm_model_${TIMESTAMP}.keras
          aws s3 cp models/gold_scaler.pkl s3://${{ secrets.S3_BUCKET }}/models/gold_scaler_${TIMESTAMP}.pkl
          aws s3 cp models/model_metadata.json s3://${{ secrets.S3_BUCKET }}/models/model_metadata_${TIMESTAMP}.json
          
          # Upload as "latest" (EC2 will pull this on startup)
          aws s3 cp models/gold_lstm_model.keras s3://${{ secrets.S3_BUCKET }}/models/latest/gold_lstm_model.keras
          aws s3 cp models/gold_scaler.pkl s3://${{ secrets.S3_BUCKET }}/models/latest/gold_scaler.pkl
          aws s3 cp models/model_metadata.json s3://${{ secrets.S3_BUCKET }}/models/latest/model_metadata.json
          
          echo "‚úÖ Models uploaded to S3"

      - name: Read training metrics
        id: metrics
        run: |
          MAPE=$(cat models/model_metadata.json | python -c "import sys, json; print(json.load(sys.stdin).get('mape', 'N/A'))")
          echo "mape=$MAPE" >> $GITHUB_OUTPUT

      - name: Send success notification
        if: success() && secrets.SNS_RETRAIN_ARN != ''
        run: |
          aws sns publish \
            --topic-arn ${{ secrets.SNS_RETRAIN_ARN }} \
            --region ${{ secrets.AWS_REGION }} \
            --subject "‚úÖ Gold Model Retrained Successfully" \
            --message "Model retraining completed on $(date).

          MAPE: ${{ steps.metrics.outputs.mape }}%
          
          New model uploaded to S3: ${{ secrets.S3_BUCKET }}/models/latest/
          
          View workflow: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"

      - name: Send failure notification
        if: failure() && secrets.SNS_RETRAIN_ARN != ''
        run: |
          aws sns publish \
            --topic-arn ${{ secrets.SNS_RETRAIN_ARN }} \
            --region ${{ secrets.AWS_REGION }} \
            --subject "‚ùå Gold Model Retraining Failed" \
            --message "Model retraining failed on $(date).
          
          Check the workflow logs: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
